{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPg0GTFeIuCmLSxDoNIJ77h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iQX4dj2HR_Uc"},"outputs":[],"source":["import yfinance as yf\n","import pandas as pd\n","import numpy as np\n","from datetime import date\n","import seaborn as sns\n","import random\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.mixture import GaussianMixture\n","\n","\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","from statsmodels.regression.linear_model import OLS\n","from statsmodels.tools import add_constant\n","\n","from arch import arch_model\n","\n","import scipy.stats as stats\n","from scipy.stats import probplot, laplace, norm, t\n","from scipy.optimize import minimize\n","from scipy.stats import ncx2\n","\n","import statsmodels.api as sm\n","from statsmodels.nonparametric.kde import KDEUnivariate\n","from statsmodels.tsa.stattools import adfuller, kpss\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.arima_process import ArmaProcess\n","\n","import pymc as pm\n","import pytensor.tensor as pt\n","import arviz as az\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","#from tensorflow.keras.utils import plot_model\n","\n","\n","######################################\n","#from pmdarima import auto_arima\n","#from diptest import diptest"]},{"cell_type":"code","source":["class CIRModel:\n","    def __init__(self, df, log_return, nfuture):\n","        self.df = df\n","        self.series = log_return\n","        self.kappa = None\n","        self.theta = None\n","        self.sigma = None\n","        self.v0 = None\n","        self.nfuture = nfuture\n","        self.trading_days = 252\n","        self.dt = 1 / self.trading_days\n","        self.rolling_rv = None\n","\n","        self.rng = np.random.default_rng(42)\n","\n","    def realized_volatility(self):\n","        # Rolling realized volatility\n","        self.df['log_return'] = np.log(self.df['Close'] / self.df['Close'].shift(1))\n","        self.rolling_rv = self.df['log_return'].groupby(self.df.index.date).apply(lambda x: np.sqrt(np.sum((x - x.mean())**2)))\n","        self.rolling_rv.dropna(inplace=True)\n","\n","        self.rolling_rv_sq = self.rolling_rv ** 2\n","        self.v0 = self.rolling_rv_sq.iloc[-self.nfuture]\n","        self.params_regression()\n","        #self.params_fit()\n","\n","    def params_regression(self):\n","        v = self.rolling_rv_sq.values\n","        v_lag = v[:-1]   # v_t\n","        v_next = v[1:]   # v_{t+1}\n","\n","        # Regression: v_next = a + b * v_lag + error #Δvt​≈κ(θ−vt​)Δt+σvt​Δt --> vt+1​=(1−κΔt)vt​+κθΔt+error\n","        X = sm.add_constant(v_lag)\n","        model = sm.OLS(v_next, X).fit()\n","        a, b = model.params\n","\n","        # Parameters\n","        self.kappa = -np.log(b) / self.dt\n","        self.theta = a / (self.kappa * self.dt)\n","\n","        # Residuals for sigma\n","        residuals = v_next - (a + b * v_lag)\n","        var_resid = np.var(residuals)\n","\n","        self.sigma = np.sqrt(var_resid / (self.dt * np.mean(v)))\n","\n","        return self.kappa, self.theta, self.sigma\n","\n","    def simulate_exact(self, n_steps):\n","        v_paths = np.zeros((self.nfuture + 1, n_steps))\n","        v_paths[0] = self.v0\n","\n","        for t in range(1, self.nfuture + 1):\n","            v_prev = v_paths[t-1]\n","            exp_kdt = np.exp(-self.kappa * dt)\n","            c = (self.sigma**2 * (1 - exp_kdt)) / (4 * self.kappa)\n","            d = 4 * self.kappa * self.theta / (self.sigma**2)\n","            lam = (4 * self.kappa * exp_kdt * v_prev) / (self.sigma**2 * (1 - exp_kdt))\n","            # sample from noncentral chi-square\n","            x = ncx2.rvs(d, lam, size=n_steps)\n","            v_paths[t] = c * x\n","\n","        return v_paths\n","\n","    def simulate_euler(self, n_steps):\n","        dt = 1 / self.trading_days\n","        v_paths = np.zeros((self.nfuture + 1, n_steps))\n","        v_paths[0] = self.v0\n","\n","        for t in range(1, self.nfuture + 1):\n","            v_prev = v_paths[t-1]\n","            # Brownian increments\n","            dW = np.random.normal(0, np.sqrt(dt), size=n_steps)\n","            # Euler-Maruyama update\n","            v_new = v_prev + self.kappa * (self.theta - v_prev) * dt + self.sigma * np.sqrt(np.maximum(v_prev, 0)) * dW\n","            v_paths[t] = np.maximum(v_new, 0)  # enforce positivity\n","\n","        return v_paths\n","\n","    def forecast_volatility(self, n_steps, alpha):\n","        \"\"\"Plot realized vs forecast with CI and forecast error.\"\"\"\n","        v_paths = self.simulate_euler(n_steps)\n","\n","        # convert variance paths -> volatility (annualized)\n","        vol_paths = np.sqrt(v_paths) * np.sqrt(self.trading_days)\n","\n","        # statistics across simulations\n","        forecast_mean = vol_paths.mean(axis=1)\n","        forecast_ci_lower = np.percentile(vol_paths, 100 * (alpha / 2), axis=1)\n","        forecast_ci_upper = np.percentile(vol_paths, 100 * (1 - alpha / 2), axis=1)\n","\n","        forecast_index = self.rolling_rv.index[-self.nfuture-1:]\n","        forecast_series = pd.Series(forecast_mean, index=forecast_index)\n","        forecast_lower = pd.Series(forecast_ci_lower, index=forecast_index)\n","        forecast_upper = pd.Series(forecast_ci_upper, index=forecast_index)\n","\n","        # realized volatility (annualized)\n","        realized_vol = self.rolling_rv * np.sqrt(self.trading_days)\n","        realized_vals = realized_vol.loc[forecast_series.index]\n","\n","        # --- Forecast errors ---\n","        # point forecast error\n","        forecast_error = (forecast_series - realized_vals) / realized_vals\n","        mae = np.mean(np.abs(forecast_error))\n","        rmse = np.sqrt(np.mean(forecast_error**2))\n","\n","        # CI coverage: % of realized values inside forecast CI\n","        inside_band = ((realized_vals >= forecast_lower) &\n","                      (realized_vals <= forecast_upper)).mean()\n","        coverage_error = 1 - inside_band  # miss rate\n","\n","        # Plotting\n","        fig, axs = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n","        start_index = -self.nfuture - 21\n","        end_index = -1\n","\n","        # Historical + Forecast\n","        axs[0].plot(realized_vol, color='black', alpha=1, label='Realized Vol')\n","        axs[0].plot(forecast_series, color='red', linestyle='--', label='CIR Forecast (Mean)')\n","        axs[0].fill_between(forecast_series.index, forecast_lower, forecast_upper,\n","                            color='blue', alpha=0.3, label=f'{100*(1-alpha):.0f}% CI')\n","        axs[0].axvline(x=forecast_series.index[0], color='black', linestyle='--', linewidth=1.5)\n","        axs[0].set_title(\n","            f'Historical Realized Volatility and CIR Forecast\\n'\n","            f'MAE={mae:.4f}, RMSE={rmse:.4f}, Coverage Error={coverage_error:.2%}'\n","        )\n","        axs[0].set_ylabel('Annualized Volatility')\n","        axs[0].legend()\n","        axs[0].grid(True)\n","        axs[0].set_xlim([realized_vol.index[start_index], realized_vol.index[end_index]])\n","        axs[0].set_ylim(0, np.amax(forecast_series) * 2)\n","\n","        # Forecast errors plot\n","        axs[1].bar(forecast_error.index, forecast_error.values * 100, color='purple')\n","        axs[1].plot(forecast_error * 100, marker='o', linestyle='--', color='purple', alpha=0.7)\n","        axs[1].axhline(0, color='black', linestyle='-')\n","        axs[1].axvline(x=forecast_series.index[0], color='black', linestyle='--', linewidth=1.5)\n","        axs[1].set_title('Relative Forecast Error (Forecast - Realized) / Realized')\n","        axs[1].set_ylabel('Relative Error')\n","        axs[1].grid(True)\n","\n","        plt.tight_layout()"],"metadata":{"id":"cZ5FIjJuj19_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##CIR --> by fitting non-central chi-squared distribution\n","\n","import numpy as np\n","import scipy.optimize as opt\n","from scipy.stats import ncx2\n","\n","def cir_negative_loglik(params, v_series, dt):\n","    \"\"\"\n","    Negative log-likelihood for CIR using exact transition density.\n","    params: array-like [kappa, theta, sigma] (all > 0)\n","    v_series: 1D numpy array of realized variances v_t\n","    dt: time step in years (e.g., 1/252)\n","    \"\"\"\n","    kappa, theta, sigma = params\n","\n","    # enforce positivity in function (minimizer may propose negatives)\n","    if kappa <= 0 or theta <= 0 or sigma <= 0:\n","        return 1e10\n","\n","    # precompute\n","    exp_kdt = np.exp(-kappa * dt)\n","    one_minus = 1.0 - exp_kdt\n","    # small guard\n","    if one_minus <= 0 or sigma <= 0 or kappa <= 0:\n","        return 1e10\n","\n","    c = (sigma**2 * one_minus) / (4.0 * kappa)\n","    d = (4.0 * kappa * theta) / (sigma**2)\n","\n","    v = v_series\n","    v_t = v[:-1]\n","    v_tp1 = v[1:]\n","\n","    # avoid zeros\n","    eps = 1e-16\n","    v_t = np.maximum(v_t, eps)\n","    v_tp1 = np.maximum(v_tp1, eps)\n","\n","    # noncentrality parameter\n","    lam = (4.0 * kappa * exp_kdt * v_t) / (sigma**2 * one_minus)\n","\n","    # scaled variable for ncx2: x = v_{t+1} / c\n","    x = v_tp1 / c\n","\n","    # compute logpdf of non-central chi-square at x with d dof and lambda\n","    # logpdf for scaled variable: log f_V(v_tp1) = logpdf_chi2(x) - log(c)\n","    # use scipy.stats.ncx2.logpdf\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        logpdf_vals = ncx2.logpdf(x, df=d, nc=lam)\n","        # subtract log(c) due to scale\n","        logpdf_vals = logpdf_vals - np.log(c)\n","\n","    # handle -inf or nan (very unlikely if x>0)\n","    if np.any(~np.isfinite(logpdf_vals)):\n","        # give large penalty\n","        return 1e10\n","\n","    neg_ll = -np.sum(logpdf_vals)\n","    return neg_ll\n","\n","def estimate_cir_mle(v_series, dt=1/252, initial_guess=None, bounds=None, enforce_feller=False):\n","    \"\"\"\n","    v_series: 1D array-like of realized variances (length T)\n","    dt: timestep in years\n","    initial_guess: optional [kappa, theta, sigma], else derived from OLS\n","    bounds: optional list of (min,max) for kappa,theta,sigma\n","    enforce_feller: if True, add constraint 2*kappa*theta >= sigma^2 via penalty\n","    \"\"\"\n","    v = np.asarray(v_series)\n","    if v.ndim != 1 or v.size < 5:\n","        raise ValueError(\"v_series must be 1D with at least several observations\")\n","\n","    # default initial guess from regression (quick method)\n","    if initial_guess is None:\n","        # simple OLS to get slope/intercept as earlier\n","        v_lag = v[:-1]\n","        v_next = v[1:]\n","        A = np.vstack([np.ones_like(v_lag), v_lag]).T\n","        beta, *_ = np.linalg.lstsq(A, v_next, rcond=None)\n","        a, b = beta  # v_next ≈ a + b * v_lag\n","        # transform to CIR approximate\n","        kappa_init = max(1e-6, -np.log(b) * (1.0/dt)) if b>0 else 1.0\n","        theta_init = max(1e-8, a / (kappa_init * dt)) if kappa_init>0 else np.mean(v)\n","        # residual-based sigma initial\n","        resid = v_next - (a + b * v_lag)\n","        var_resid = np.var(resid, ddof=1)\n","        sigma_init = np.sqrt(max(var_resid / (dt * np.mean(v)), 1e-8))\n","        initial_guess = np.array([kappa_init, theta_init, sigma_init])\n","\n","    # bounds default\n","    if bounds is None:\n","        bounds = [(1e-8, 50.0),    # kappa\n","                  (1e-12, np.max(v)*10 + 1.0),  # theta\n","                  (1e-8, 5.0)]     # sigma\n","\n","    # objective with optional feller penalty\n","    def obj(par):\n","        val = cir_negative_loglik(par, v, dt)\n","        if enforce_feller:\n","            k, th, s = par\n","            penalty = 0.0\n","            if 2.0*k*th < s*s:\n","                # quadratic penalty\n","                gap = s*s - 2.0*k*th\n","                penalty = 1e6 * gap**2\n","            val = val + penalty\n","        return val\n","\n","    result = opt.minimize(obj, x0=initial_guess, bounds=bounds, method='L-BFGS-B',\n","                          options={'disp': False, 'maxiter': 1000})\n","\n","    if not result.success:\n","        # you may still return the best found\n","        # print(\"Optimization did not converge:\", result.message)\n","        pass\n","\n","    est = result.x\n","    return {'kappa': float(est[0]), 'theta': float(est[1]), 'sigma': float(est[2]),\n","            'success': result.success, 'message': result.message, 'initial_guess': initial_guess}\n","\n","# Example usage:\n","# v_series = cir_calibration.rolling_rv_sq.values  # from your realized_volatility() routine\n","# res = estimate_cir_mle(v_series, dt=1/252)\n","# print(res)\n"],"metadata":{"id":"LOa9NueegVRW"},"execution_count":null,"outputs":[]}]}